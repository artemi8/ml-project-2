{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc34b741-d4ac-4076-bc32-756b2146f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.impute import KNNImputer\n",
    "import imblearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, balanced_accuracy_score\n",
    "from scipy.stats import skew\n",
    "from sklearn.manifold import TSNE # TSNE module\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from utils.general_utils import get_outlier_info, get_outlier_val_counts, clean_outliers\n",
    "from utils.saver_utils import save_normalizer, load_normalizer\n",
    "from utils.saver_utils import save_dataset, load_dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69f44bcb-ed76-4002-9dc5-c370deda5765",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_df = pd.read_csv('dataset/TrainDataset2023.csv')\n",
    "og_df.rename(columns={'pCR (outcome)': 'pcr', 'RelapseFreeSurvival (outcome)': 'rfs'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545f7af0-2adb-4e20-bfa7-9f719ef9fab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pcr',\n",
       " 'ER',\n",
       " 'PgR',\n",
       " 'HER2',\n",
       " 'TrippleNegative',\n",
       " 'ChemoGrade',\n",
       " 'Proliferation',\n",
       " 'HistologyType',\n",
       " 'LNStatus',\n",
       " 'TumourStage']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_col_mask = og_df.drop(columns=['ID']).dtypes == 'int64'\n",
    "categorical_features = list(og_df.drop(columns=['ID']).columns[int_col_mask])\n",
    "\n",
    "# Ignoring 'original_shape_VoxelVolume' because even though it is a int column it is not a categorical feature\n",
    "\n",
    "categorical_features.remove('original_shape_VoxelVolume')\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b88cada-1af8-452e-9971-f8425a0a9bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 25]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_col_index = [i for i, x in enumerate(np.array(int_col_mask)) if x]\n",
    "int_col_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b399c4-7d95-44ac-b119-1877ad4702ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pcr                5\n",
       "PgR                1\n",
       "HER2               1\n",
       "TrippleNegative    1\n",
       "ChemoGrade         3\n",
       "Proliferation      2\n",
       "HistologyType      3\n",
       "LNStatus           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_vals = np.sum(og_df == 999)\n",
    "missing_cols_valuecounts = missing_vals[missing_vals > 0]\n",
    "missing_cols_valuecounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811cc2a4-2d6d-4abe-b4ad-88e2904ee3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a7ec5ba-9759-4aa2-abed-cedee272f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_knn = KNNImputer(n_neighbors=3, missing_values=999)\n",
    "imputed_arr = impute_knn.fit_transform(og_df.drop(columns=['ID']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f42d5b2d-1a0d-414f-9391-1d7bdd40de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in int_col_index:\n",
    "    imputed_arr[:, idx] = np.rint(imputed_arr[:, idx])\n",
    "\n",
    "imputed_df = pd.DataFrame.from_records(imputed_arr, columns=og_df.columns[1:])\n",
    "\n",
    "# skew_processing_cols = imputed_df.drop(columns = set(categorical_features).union({'pcr', 'rfs'})).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c00fdd8-87cc-4b28-8862-fcc855d43c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ChemoGrade', 'Proliferation', 'TumourStage'], [2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_categorical_features = []\n",
    "others = []\n",
    "\n",
    "for cat_col_name in categorical_features:\n",
    "    temp_len = len(imputed_df[cat_col_name].value_counts())\n",
    "    if temp_len > 2:\n",
    "        multiclass_categorical_features.append(cat_col_name)\n",
    "    else:\n",
    "        others.append(temp_len)\n",
    "\n",
    "multiclass_categorical_features, others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8aaedb5-c9e3-43e6-8d91-6c33045241ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = pd.get_dummies(imputed_df, columns=multiclass_categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b1a342-48c0-445f-bad2-2e35433b5a01",
   "metadata": {},
   "source": [
    "# Converting bool one hot encoding to integer one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa377a5d-68d8-4534-8fab-1b3f4ae2112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_category_variables = ['ChemoGrade_1.0', 'ChemoGrade_2.0', 'ChemoGrade_3.0', 'Proliferation_1.0', 'Proliferation_2.0',\n",
    "       'Proliferation_3.0', 'TumourStage_1.0', 'TumourStage_2.0', 'TumourStage_3.0', 'TumourStage_4.0']\n",
    "\n",
    "for column in multi_category_variables:\n",
    "    imputed_df[column] = imputed_df[column].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c487499-a1d4-4bc5-89b8-0d2f47e22a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Columns : Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "nan_cols = imputed_df.columns[imputed_df.isnull().sum() > 0]\n",
    "\n",
    "print(f'NaN Columns : {nan_cols}')\n",
    "if len(nan_cols) > 0:\n",
    "    imputed_df.drop(columns=nan_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e8836a-e9f8-4191-b286-7367bf6b5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_labels = categorical_features + multi_category_variables\n",
    "temp_categorical_features_labels = categorical_features_labels\n",
    "\n",
    "# Removing multiclass_categorical_features because these features are \n",
    "#converted to one-hot encoding\n",
    "\n",
    "for col_name in multiclass_categorical_features:\n",
    "    temp_categorical_features_labels.remove(col_name)\n",
    "\n",
    "temp_categorical_features_labels.remove('pcr')\n",
    "\n",
    "continous_features_labels = imputed_df.drop(columns=temp_categorical_features_labels+['pcr', 'rfs']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1e6bea0-3c7a-4bf8-a0fe-9d5ea0bd0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(imputed_df, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93dfa391-285f-409f-b69c-4f978cd7b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_continous_feature_array = train[continous_features_labels].to_numpy()\n",
    "\n",
    "test_continous_feature_array = test[continous_features_labels].to_numpy()\n",
    "\n",
    "scalerTrainX = StandardScaler()\n",
    "scalerTrainY = StandardScaler()\n",
    "# scalerTrainX = RobustScaler()\n",
    "# scalerTrainY = RobustScaler()\n",
    "\n",
    "# scalerTrainX = MinMaxScaler()\n",
    "# scalerTrainY = MinMaxScaler()\n",
    "\n",
    "\n",
    "train_cont_X = scalerTrainX.fit_transform(train_continous_feature_array)\n",
    "train_cat_X = train[temp_categorical_features_labels].to_numpy()\n",
    "trainX = np.hstack((train_cat_X, train_cont_X))\n",
    "                   \n",
    "trainY = scalerTrainY.fit_transform(train['rfs'].to_numpy().reshape(-1, 1))\n",
    "# trainY = train['rfs'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "\n",
    "                   \n",
    "test_cont_X = scalerTrainX.transform(test_continous_feature_array)\n",
    "test_cat_X = test[temp_categorical_features_labels].to_numpy()\n",
    "testX = np.hstack((test_cat_X, test_cont_X))\n",
    "                   \n",
    "testY = scalerTrainY.transform(test['rfs'].to_numpy().reshape(-1, 1))\n",
    "# testY = test['rfs'].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaaf40c0-7904-4d3b-921a-a3b77994f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(trainX, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(trainY, dtype=torch.float32).view(-1, 1)  # Ensure y is a column vector\n",
    "\n",
    "X_test_tensor = torch.tensor(testX, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(testY, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46fbfe45-889a-4573-8abc-8dfd547f9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network model\n",
    "class SimpleANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate=0.3):\n",
    "        super(SimpleANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 32)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # self.fc3 = nn.Linear(64, 128)\n",
    "        # self.relu3 = nn.ReLU()\n",
    "        # self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc4 = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f85c9eee-d3f5-4ce9-a3b9-ca042cb92deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2: -0.1484821265388756\n",
      "Test MAE: 0.8794056\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "input_size = trainX.shape[1]\n",
    "hidden_size = 64  # You can adjust this as needed\n",
    "output_size = 1\n",
    "model = SimpleANN(input_size, hidden_size, output_size, dropout_rate=0.5)\n",
    "\n",
    "# Define L2 regularization strength\n",
    "l2_lambda = 0.001\n",
    "# l2_lambda = 0\n",
    "\n",
    "\n",
    "# Define the loss function with L2 regularization\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=l2_lambda)\n",
    "\n",
    "# Create DataLoader for batch training\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # L2 regularization\n",
    "        l2_reg = sum(torch.norm(param) for param in model.parameters())\n",
    "        loss += l2_lambda * l2_reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    test_r2 = r2_score(y_test_tensor.numpy(), test_predictions.numpy())\n",
    "    test_mae = mean_absolute_error(y_test_tensor.numpy(), test_predictions.numpy())\n",
    "\n",
    "print(\"Test R2:\", test_r2)\n",
    "print(\"Test MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3150ba8c-7432-4dd1-b6e4-66083bddfe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.690174789518419\n",
      "Train MAE: 0.43967095\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_train_tensor)\n",
    "    test_r2 = r2_score(y_train_tensor.numpy(), test_predictions.numpy())\n",
    "    test_mae = mean_absolute_error(y_train_tensor.numpy(), test_predictions.numpy())\n",
    "\n",
    "print(\"Train R2:\", test_r2)\n",
    "print(\"Train MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dff14d-29e9-4c94-9578-e21e3a3265aa",
   "metadata": {},
   "source": [
    "# With Dataset V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05576ec-09db-4bf1-a860-d2766e13a49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pcr</th>\n",
       "      <th>rfs</th>\n",
       "      <th>Age</th>\n",
       "      <th>ER</th>\n",
       "      <th>PgR</th>\n",
       "      <th>LNStatus</th>\n",
       "      <th>original_shape_Elongation</th>\n",
       "      <th>original_shape_Flatness</th>\n",
       "      <th>original_shape_LeastAxisLength</th>\n",
       "      <th>original_shape_MajorAxisLength</th>\n",
       "      <th>...</th>\n",
       "      <th>ChemoGrade_1.0</th>\n",
       "      <th>ChemoGrade_2.0</th>\n",
       "      <th>ChemoGrade_3.0</th>\n",
       "      <th>Proliferation_1.0</th>\n",
       "      <th>Proliferation_2.0</th>\n",
       "      <th>Proliferation_3.0</th>\n",
       "      <th>TumourStage_1.0</th>\n",
       "      <th>TumourStage_2.0</th>\n",
       "      <th>TumourStage_3.0</th>\n",
       "      <th>TumourStage_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.813912</td>\n",
       "      <td>0.724080</td>\n",
       "      <td>23.781937</td>\n",
       "      <td>32.844370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666118</td>\n",
       "      <td>0.476173</td>\n",
       "      <td>20.715461</td>\n",
       "      <td>43.504095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645083</td>\n",
       "      <td>0.594470</td>\n",
       "      <td>21.659822</td>\n",
       "      <td>36.435505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770842</td>\n",
       "      <td>0.501228</td>\n",
       "      <td>26.590504</td>\n",
       "      <td>53.050724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.861035</td>\n",
       "      <td>0.750267</td>\n",
       "      <td>20.456571</td>\n",
       "      <td>27.265716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pcr    rfs   Age   ER  PgR  LNStatus  original_shape_Elongation  \\\n",
       "0  1.0  144.0  41.0  0.0  0.0       1.0                   0.813912   \n",
       "1  0.0  142.0  39.0  1.0  1.0       1.0                   0.666118   \n",
       "2  1.0  135.0  31.0  0.0  0.0       0.0                   0.645083   \n",
       "3  0.0   12.0  35.0  0.0  0.0       1.0                   0.770842   \n",
       "4  0.0  109.0  61.0  1.0  0.0       0.0                   0.861035   \n",
       "\n",
       "   original_shape_Flatness  original_shape_LeastAxisLength  \\\n",
       "0                 0.724080                       23.781937   \n",
       "1                 0.476173                       20.715461   \n",
       "2                 0.594470                       21.659822   \n",
       "3                 0.501228                       26.590504   \n",
       "4                 0.750267                       20.456571   \n",
       "\n",
       "   original_shape_MajorAxisLength  ...  ChemoGrade_1.0  ChemoGrade_2.0  \\\n",
       "0                       32.844370  ...             0.0             0.0   \n",
       "1                       43.504095  ...             0.0             0.0   \n",
       "2                       36.435505  ...             0.0             1.0   \n",
       "3                       53.050724  ...             0.0             0.0   \n",
       "4                       27.265716  ...             0.0             1.0   \n",
       "\n",
       "   ChemoGrade_3.0  Proliferation_1.0  Proliferation_2.0  Proliferation_3.0  \\\n",
       "0             1.0                0.0                0.0                1.0   \n",
       "1             1.0                0.0                0.0                1.0   \n",
       "2             0.0                1.0                0.0                0.0   \n",
       "3             1.0                0.0                0.0                1.0   \n",
       "4             0.0                1.0                0.0                0.0   \n",
       "\n",
       "   TumourStage_1.0  TumourStage_2.0  TumourStage_3.0  TumourStage_4.0  \n",
       "0              0.0              1.0              0.0              0.0  \n",
       "1              0.0              1.0              0.0              0.0  \n",
       "2              0.0              1.0              0.0              0.0  \n",
       "3              0.0              0.0              1.0              0.0  \n",
       "4              0.0              1.0              0.0              0.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetv2_save_path = \"dataset/dataset_v2\"\n",
    "imputed_df = pd.read_csv(f'{datasetv2_save_path}/imputed_df.csv', index_col=0)\n",
    "imputed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9da386d6-1d6d-4de7-a6fe-4eb6109d33ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(imputed_df, test_size=0.20)\n",
    "\n",
    "multi_category_variables = ['ChemoGrade_1.0', 'ChemoGrade_2.0', 'ChemoGrade_3.0', 'Proliferation_1.0', 'Proliferation_2.0',\n",
    "       'Proliferation_3.0', 'TumourStage_1.0', 'TumourStage_2.0', 'TumourStage_3.0', 'TumourStage_4.0']\n",
    "\n",
    "categorical_features_labels = ['ER', 'PgR', 'LNStatus'] + multi_category_variables\n",
    "\n",
    "continous_features_labels = imputed_df.drop(columns=categorical_features_labels+['pcr', 'rfs']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8babfc28-1824-4e50-bf7c-ec4361f43b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_continous_feature_array = train[continous_features_labels].to_numpy()\n",
    "\n",
    "test_continous_feature_array = test[continous_features_labels].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ddb7747-14f5-4e7e-ba5f-76a9a4b7574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalerTrainX = StandardScaler()\n",
    "# scalerTrainY = StandardScaler()\n",
    "# scalerTrainX = RobustScaler()\n",
    "# scalerTrainY = RobustScaler()\n",
    "\n",
    "scalerTrainX = MinMaxScaler()\n",
    "scalerTrainY = MinMaxScaler()\n",
    "\n",
    "\n",
    "train_cont_X = scalerTrainX.fit_transform(train_continous_feature_array)\n",
    "train_cat_X = train[categorical_features_labels].to_numpy()\n",
    "trainX = np.hstack((train_cat_X, train_cont_X))\n",
    "                   \n",
    "trainY = scalerTrainY.fit_transform(train['rfs'].to_numpy().reshape(-1, 1))\n",
    "\n",
    "                   \n",
    "test_cont_X = scalerTrainX.transform(test_continous_feature_array)\n",
    "test_cat_X = test[categorical_features_labels].to_numpy()\n",
    "testX = np.hstack((test_cat_X, test_cont_X))\n",
    "                   \n",
    "testY = scalerTrainY.transform(test['rfs'].to_numpy().reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d67ff71d-296d-4cfa-9c15-1ced98bd9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize the features\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(trainX, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(trainY, dtype=torch.float32).view(-1, 1)  # Ensure y is a column vector\n",
    "\n",
    "X_test_tensor = torch.tensor(testX, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(testY, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220f958-136d-4058-9c32-3bcb92db6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3864d806-089b-41b6-ad4f-c1b0ea77a511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2: 0.03278682452449455\n",
      "Test MAE: 0.14895019\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "input_size = trainX.shape[1]\n",
    "hidden_size = 64  # You can adjust this as needed\n",
    "output_size = 1\n",
    "model = SimpleANN(input_size, hidden_size, output_size, dropout_rate=0.5)\n",
    "\n",
    "# Define L2 regularization strength\n",
    "l2_lambda = 0.001\n",
    "# l2_lambda = 0\n",
    "\n",
    "\n",
    "# Define the loss function with L2 regularization\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=l2_lambda)\n",
    "\n",
    "# Create DataLoader for batch training\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # L2 regularization\n",
    "        l2_reg = sum(torch.norm(param) for param in model.parameters())\n",
    "        loss += l2_lambda * l2_reg\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    test_r2 = r2_score(y_test_tensor.numpy(), test_predictions.numpy())\n",
    "    test_mae = mean_absolute_error(y_test_tensor.numpy(), test_predictions.numpy())\n",
    "\n",
    "print(\"Test R2:\", test_r2)\n",
    "print(\"Test MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f624c8e-4936-4f8f-8a2a-a224050f60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.19732078520909635\n",
      "Train MAE: 0.13220277\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_train_tensor)\n",
    "    test_r2 = r2_score(y_train_tensor.numpy(), test_predictions.numpy())\n",
    "    test_mae = mean_absolute_error(y_train_tensor.numpy(), test_predictions.numpy())\n",
    "\n",
    "print(\"Train R2:\", test_r2)\n",
    "print(\"Train MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a09d1-6fda-43ea-9431-e1ea88124e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
