{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T01gL7SJPVbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16c8f68-fb8a-412d-a3de-2ef017d1af3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1O10h52XJJKnQl5oj68nWHQ0bXf8_Y38V\n",
            "To: /content/syntetic_train.csv\n",
            "100% 195k/195k [00:00<00:00, 69.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Wdo7ywkP6H-CUYZ7tOym7A5bOLlBMdrc\n",
            "To: /content/original_test.csv\n",
            "100% 23.2k/23.2k [00:00<00:00, 39.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12na5PZOb0G-APQgrvGaDSa3_Qdx4xEHY\n",
            "To: /content/MLP.pth\n",
            "100% 10.6k/10.6k [00:00<00:00, 23.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1W-5EsxP6l7z4YHxC40wcOeigl4KqXYdm\n",
            "To: /content/MLP_CNN1d.pth\n",
            "100% 9.10k/9.10k [00:00<00:00, 22.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "#### Uncomment to download data and trained weights\n",
        "!gdown 1O10h52XJJKnQl5oj68nWHQ0bXf8_Y38V ## Train Synthetic Data\n",
        "!gdown 1Wdo7ywkP6H-CUYZ7tOym7A5bOLlBMdrc ## Original Test Data\n",
        "!gdown 12na5PZOb0G-APQgrvGaDSa3_Qdx4xEHY ## MLP weights\n",
        "!gdown 1W-5EsxP6l7z4YHxC40wcOeigl4KqXYdm ## CNN1D_MLP weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Required Libs"
      ],
      "metadata": {
        "id": "0U_yKZQoejpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from string import ascii_letters\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, balanced_accuracy_score"
      ],
      "metadata": {
        "id": "p2PFjlHdek_v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_synthetic_train = pd.read_csv('/content/syntetic_train.csv')\n",
        "df_original_test   = pd.read_csv('/content/original_test.csv')"
      ],
      "metadata": {
        "id": "sy__cyupe6Vo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nolmalise using MinMax scaling on target\n",
        "# MinMax Scaling\n",
        "\n",
        "min_train = df_synthetic_train['RelapseFreeSurvival (outcome)'].min()\n",
        "max_train = df_synthetic_train['RelapseFreeSurvival (outcome)'].max()\n",
        "\n",
        "min_test = df_original_test['RelapseFreeSurvival (outcome)'].min()\n",
        "max_test = df_original_test['RelapseFreeSurvival (outcome)'].max()\n",
        "\n",
        "df_synthetic_train['RelapseFreeSurvival (outcome)'] = (df_synthetic_train['RelapseFreeSurvival (outcome)'] - min_train)/(max_train - min_train)\n",
        "df_original_test['RelapseFreeSurvival (outcome)']   = (df_original_test['RelapseFreeSurvival (outcome)'] - min_test)/(max_test - min_test)"
      ],
      "metadata": {
        "id": "Q_j9lngWeyGL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defined Models"
      ],
      "metadata": {
        "id": "vynqj8ZHeDPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class MLP_Regressor(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(MLP_Regressor, self).__init__()\n",
        "\n",
        "        self.cf1 = nn.Linear(input_shape, 32)\n",
        "\n",
        "        self.cf2 = nn.Linear(32, 16)\n",
        "        self.cf3 = nn.Linear(16, 1)\n",
        "\n",
        "        self.relu    = nn.ReLU()\n",
        "        self.batchnorm1 = nn.BatchNorm1d(32)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(16)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x  = self.relu(self.batchnorm1(self.cf1(x)))\n",
        "        x  = self.dropout1(x)\n",
        "        x  = self.relu(self.batchnorm2(self.cf2(x)))\n",
        "        x  = self.cf3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class CNN1D_Regressor(nn.Module):\n",
        "    def __init__(self, input_shape):\n",
        "        super(CNN1D_Regressor, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv1d(1, 2, 2, stride=2)\n",
        "        self.cnn2 = nn.Conv1d(2, 4, 4, stride=3)\n",
        "\n",
        "        self.cf1 = nn.Linear(input_shape, 16)\n",
        "        self.cf2 = nn.Linear(8, 1)\n",
        "\n",
        "        self.relu    = nn.ReLU()\n",
        "\n",
        "        self.batchnorm1 = nn.BatchNorm1d(2)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(4)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(8)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.cf1(x))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.unsqueeze(x, 1)\n",
        "        x = self.batchnorm1(self.relu(self.cnn1(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.batchnorm2(self.relu(self.cnn2(x)))\n",
        "\n",
        "        x = torch.reshape(x, (x.shape[0], x.shape[1] * x.shape[2]))\n",
        "\n",
        "        x = self.cf2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "LtyG9BoDShdh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "wc9FXxXGtbT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def MLP_RegressorLoop(model, criterion, optimizer, scheduler, epochs, X_train, y_train, X_val, y_val):\n",
        "#     val_loss_his = []\n",
        "#     train_loss_his = []\n",
        "#     count = 1\n",
        "#     MODEL = []\n",
        "#     for eph in range(epochs):\n",
        "#         loss_epoch_train = []\n",
        "#         loss_epoch_val = []\n",
        "\n",
        "#         model.train()\n",
        "\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "\n",
        "#         output = model(X_train)\n",
        "\n",
        "#         loss = criterion(output, y_train.unsqueeze(1))\n",
        "\n",
        "#         loss_epoch_train.append(loss.cpu().detach().numpy())\n",
        "\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         train_loss_his.append(np.mean(loss_epoch_train))\n",
        "\n",
        "#         # Run the validation batches\n",
        "#         model.eval()\n",
        "#         with torch.no_grad():\n",
        "\n",
        "#             X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "\n",
        "#             out_val = model(X_val)\n",
        "\n",
        "#             loss = criterion(out_val.cpu(), y_val.cpu())\n",
        "\n",
        "#             loss_epoch_val.append(loss.item())\n",
        "\n",
        "#         val_loss_his.append(np.mean(loss_epoch_val))\n",
        "#         scheduler.step(np.mean(loss_epoch_val))\n",
        "\n",
        "#         print('MSE', loss.numpy())\n",
        "\n",
        "#         if eph > 1:\n",
        "#             if np.mean(loss_epoch_val) < min(val_loss_his[0:-1]):\n",
        "#                 count = 0\n",
        "#                 print(str(eph) + ' Val loss improve form!! :' + str(min(val_loss_his[0:-1])) + ' to ' + str(np.mean(loss_epoch_val)) )\n",
        "#                 MODEL.append(model)\n",
        "#                 # print('------------------Save Model!----------------')\n",
        "\n",
        "#             if np.mean(loss_epoch_val) > min(val_loss_his[0:-1]):\n",
        "#                 # print('Val loss is not improve form ' + str(min(val_loss_his))  )\n",
        "#                 count += 1\n",
        "#                 if count == 10:\n",
        "#                     print('Stop Training')\n",
        "\n",
        "#                     return MODEL[-1]\n",
        "\n",
        "#                     break"
      ],
      "metadata": {
        "id": "9es8nzaYefux"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set train test validation, exclude label column\n",
        "dftrain = df_synthetic_train[df_synthetic_train.columns[1:]].values.tolist()[40:]\n",
        "dfval   = df_synthetic_train[df_synthetic_train.columns[1:]].values.tolist()[0:40]\n",
        "dftest  = df_original_test[df_original_test.columns[1:]].values.tolist()\n",
        "\n",
        "y_train = df_synthetic_train['RelapseFreeSurvival (outcome)'].reset_index(drop=True)[40:]\n",
        "y_val   = df_synthetic_train['RelapseFreeSurvival (outcome)'].reset_index(drop=True)[0:40]\n",
        "y_test  = df_original_test['RelapseFreeSurvival (outcome)'].reset_index(drop=True)\n",
        "\n",
        "# To pytorch tensor\n",
        "X_train = torch.tensor(dftrain, dtype=torch.float32)\n",
        "X_val   = torch.tensor(dfval, dtype=torch.float32)\n",
        "X_test  = torch.tensor(dftest, dtype=torch.float32)\n",
        "\n",
        "y_train = torch.tensor(y_train.tolist(), dtype=torch.float32)\n",
        "y_val   = torch.tensor(y_val.tolist(), dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test.tolist(), dtype=torch.float32)"
      ],
      "metadata": {
        "id": "jeJNuVk1flvb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment if you want to train\n",
        "# epochs = 200\n",
        "# # model = CNN1D_Regressor(X_train.shape[-1]) # Create model CNN1D\n",
        "# model = MLP_Regressor(X_train.shape[-1]) # Create model CNN1D\n",
        "\n",
        "# criterion = nn.MSELoss() # nn.L1Loss()# nn.MSELoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr= 0.01)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.6,\n",
        "#                                      patience=5, min_lr= 0.00001 ,verbose = True)\n",
        "\n",
        "# model_trained = MLP_RegressorLoop(model, criterion, optimizer, scheduler, epochs,\n",
        "#                                     X_train, y_train, X_val, y_val)"
      ],
      "metadata": {
        "id": "AHNMBjOfehw5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Weights\n",
        "# torch.save(model_trained.state_dict(), \"/content/MLP_CNN1d.pth\") # CNN1D_MLP\n",
        "# torch.save(model_trained.state_dict(), \"/content/MLP.pth\") # MLP"
      ],
      "metadata": {
        "id": "VOMVH3sqq8_w"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Models\n",
        "# model_trained = CNN1D_Regressor(X_train.shape[-1]) # Create CNN1D_MLP\n",
        "model_trained = MLP_Regressor(X_train.shape[-1]) # Create MLP"
      ],
      "metadata": {
        "id": "cSHTHEoQsSyB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Weights\n",
        "# model_trained.load_state_dict(torch.load(\"/content/MLP_CNN1d.pth\")) # CNN1D_MLP\n",
        "model_trained.load_state_dict(torch.load(\"/content/MLP.pth\")) # MLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys7Gbf6FsGqP",
        "outputId": "2c940235-0f0d-49f3-b920-d5b30da18eaf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "model_trained.eval()\n",
        "with torch.no_grad():\n",
        "  prd = model_trained(X_test)\n",
        "\n",
        "print('R2 ', r2_score(y_test, prd))\n",
        "print('MAE ', mean_absolute_error(y_test, prd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uagRjSBngJ6C",
        "outputId": "1ba995d1-d9d2-45da-811b-2ab4b0f7327e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2  -0.009025655389458986\n",
            "MAE  0.15294528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4o3LF9xVmYuh"
      },
      "execution_count": 1155,
      "outputs": []
    }
  ]
}